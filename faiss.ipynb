{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fafd48fc",
   "metadata": {},
   "source": [
    "We will learn using the Facebook AI Similarity Search Database. Likewise we will also look other Database. FAISS is an open source database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a5ecf",
   "metadata": {},
   "source": [
    "We will first create an environment. For this we will install conda distribution. There is also another diostribution called uv which is very good dependency resolver. UV will be discussed later on.\n",
    "\n",
    "We want to use python 3.10 so use:    conda create -n vectorDB python=3.10\n",
    "\n",
    "To activate an environment: conda activate vectorDB\n",
    "\n",
    "To deactivate:  conda deactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554ba306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp310-cp310-macosx_14_0_arm64.whl.metadata (5.1 kB)\n",
      "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/vectorDB/lib/python3.10/site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.12.0-cp310-cp310-macosx_14_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, faiss-cpu\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [faiss-cpu]\n",
      "\u001b[1A\u001b[2KSuccessfully installed faiss-cpu-1.12.0 numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd894725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/vectorDB/lib/python3.10/site-packages (2.2.6)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-macosx_10_9_universal2.whl (207 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [requests]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178b1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS is installed and now we require data. Here we just copy from a website. But we can use any other unstructured source of data like pdf, json\n",
    "\n",
    "data = \"\"\"  General research interests topics are Wireless Communication, Cooperative Cognitive Communication, Wireless Sensor Networks (WSNs), \n",
    "and Internet of Things (IoT). Currently, I am involved with secure wireless communication for the future generation networks using physical \n",
    "layer security techniques.\n",
    "\n",
    "Doctoral Thesis \n",
    "\n",
    "Research Topic: Physical Layer Security for V2X-enabled Cooperative and Cognitive Relay Networks.\n",
    "\n",
    "Supervisor: Dr. Suneel Yadav, Assistant Professor, IIIT Allahabad.\n",
    "\n",
    "Brief Overview: Cooperative vehicular relaying networks (CVRNs) support various key intelligent transportation \n",
    "application services such as traffic management, payment services, infotainment etc. These CVRNs are paving the \n",
    "way for the development of a new paradigm called Internet of Vehicles (IoV). Such networks will require the information exchange \n",
    "to occur between the vehicles, infrastructure, users, and the Internet mostly over an open and vulnerable wireless medium. \n",
    "Thus securing the transmissions at the physical layer becomes essential. The objective in this work is to investigate the \n",
    "potential benefits of physical layer security (PHY-security) for providing information security in CVRNs under cognitive and non-cognitive scenarios.\n",
    "\n",
    "M.Tech. Thesis\n",
    "\n",
    "Research Topic: Intra-Cluster Community Mechanism for Energy Efficiency and Data Resolution in Wireless Sensor Network.\n",
    "\n",
    "Supervisor: Dr. K.K. Pattanaik, Associate Professor, ABV-IIITM Gwalior.\n",
    "\n",
    "Brief Overview: Clustering scheme is effective in large scale densely deployed Wireless Sensor Networks (WSN). \n",
    "Performing data aggregation at cluster head (CH) or compressing the data traffic originating from spatially correlated nodes \n",
    "does not resolve the redundant traffic within the cluster and causes energy wastage. Selecting one node at a time among the \n",
    "correlated ones affects the data resolution. The novelty of this work lied in eliminating the redundant transmissions \n",
    "through designing a novel community of spatially correlated nodes within the cluster and then using average consensus \n",
    "mechanism for an efficient data aggregation. The above mechanism resulted in considerable reduction of redundant traffic, energy consumption, channel \n",
    "contention and better GTS slot assignment while preserving data resolution. The above system was verified through both mathematical and \n",
    "simulation in OPNET Network simulator.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e343bf",
   "metadata": {},
   "source": [
    "Lets now break down this data into small small fragments of some fixed size. We need to keep some overlap between these segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c85926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2377"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = data.strip()\n",
    "\n",
    "# The above step removes the leading and trailing spaces from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c085372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaking the data into small chunks of fixed size with some overlap\n",
    "max_char = 400\n",
    "overlap = 100\n",
    "\n",
    "# Overlap is required to maintain the relatisonship and maintain some context between the segments\n",
    "\n",
    "chunks = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(clean_data):\n",
    "    piece = clean_data[i:i+max_char]\n",
    "    chunks.append(piece)\n",
    "    i += max_char - overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4925a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['General research interests topics are Wireless Communication, Cooperative Cognitive Communication, Wireless Sensor Networks (WSNs), \\nand Internet of Things (IoT). Currently, I am involved with secure wireless communication for the future generation networks using physical \\nlayer security techniques.\\n\\nDoctoral Thesis \\n\\nResearch Topic: Physical Layer Security for V2X-enabled Cooperative and Cognitiv',\n",
       " '\\n\\nDoctoral Thesis \\n\\nResearch Topic: Physical Layer Security for V2X-enabled Cooperative and Cognitive Relay Networks.\\n\\nSupervisor: Dr. Suneel Yadav, Assistant Professor, IIIT Allahabad.\\n\\nBrief Overview: Cooperative vehicular relaying networks (CVRNs) support various key intelligent transportation \\napplication services such as traffic management, payment services, infotainment etc. These CVRNs are ',\n",
       " 'pplication services such as traffic management, payment services, infotainment etc. These CVRNs are paving the \\nway for the development of a new paradigm called Internet of Vehicles (IoV). Such networks will require the information exchange \\nto occur between the vehicles, infrastructure, users, and the Internet mostly over an open and vulnerable wireless medium. \\nThus securing the transmissions at',\n",
       " 'the Internet mostly over an open and vulnerable wireless medium. \\nThus securing the transmissions at the physical layer becomes essential. The objective in this work is to investigate the \\npotential benefits of physical layer security (PHY-security) for providing information security in CVRNs under cognitive and non-cognitive scenarios.\\n\\nM.Tech. Thesis\\n\\nResearch Topic: Intra-Cluster Community Mech',\n",
       " 'cognitive and non-cognitive scenarios.\\n\\nM.Tech. Thesis\\n\\nResearch Topic: Intra-Cluster Community Mechanism for Energy Efficiency and Data Resolution in Wireless Sensor Network.\\n\\nSupervisor: Dr. K.K. Pattanaik, Associate Professor, ABV-IIITM Gwalior.\\n\\nBrief Overview: Clustering scheme is effective in large scale densely deployed Wireless Sensor Networks (WSN). \\nPerforming data aggregation at cluster',\n",
       " 'large scale densely deployed Wireless Sensor Networks (WSN). \\nPerforming data aggregation at cluster head (CH) or compressing the data traffic originating from spatially correlated nodes \\ndoes not resolve the redundant traffic within the cluster and causes energy wastage. Selecting one node at a time among the \\ncorrelated ones affects the data resolution. The novelty of this work lied in eliminati',\n",
       " 'e among the \\ncorrelated ones affects the data resolution. The novelty of this work lied in eliminating the redundant transmissions \\nthrough designing a novel community of spatially correlated nodes within the cluster and then using average consensus \\nmechanism for an efficient data aggregation. The above mechanism resulted in considerable reduction of redundant traffic, energy consumption, channel',\n",
       " 'above mechanism resulted in considerable reduction of redundant traffic, energy consumption, channel \\ncontention and better GTS slot assignment while preserving data resolution. The above system was verified through both mathematical and \\nsimulation in OPNET Network simulator.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46e6b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next action is to obtain the embedding or vector space\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(text):\n",
    "    url = \"https://api.euron.one/api/v1/euri/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer euri-37b9fff3358867bfbeab3928b39f637bb00e12d253459000b0794bd0c4177b7f\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\": text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb08a2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03319761 -0.01910552 -0.00547118 ...  0.00032168 -0.00030704\n",
      "  0.02384648]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.03735477 -0.02227229 -0.03486598 ... -0.00266737  0.015094\n",
      "  0.02302123]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.02712595 -0.01438375  0.05812704 ... -0.00173069 -0.00612218\n",
      "  0.03404199]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.0562048   0.03134195 -0.00875073 ... -0.01135816 -0.0010601\n",
      "  0.0051227 ]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.05124796  0.03914956  0.00615395 ... -0.00534215  0.02914613\n",
      "  0.01050099]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.0493216  -0.01986492  0.05524438 ...  0.00437657 -0.01371937\n",
      "  0.00391467]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.04729202 -0.02137262  0.04288136 ... -0.00247589  0.00701076\n",
      "  0.01370162]\n",
      "(1536,)\n",
      "\n",
      "\n",
      "[ 0.0173463  -0.01873289  0.02283721 ... -0.00226188  0.02077119\n",
      " -0.00877021]\n",
      "(1536,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in chunks:\n",
    "    embedding = generate_embeddings(i)\n",
    "    print(embedding)\n",
    "    print(embedding.shape)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6ad99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = []\n",
    "meta = []\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    vec = generate_embeddings(chunk)\n",
    "    emb_list.append(vec.astype('float32'))\n",
    "    meta.append({\"chunk_id\": idx, \"chunk\": chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4cfcbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03319762, -0.01910552, -0.00547118, ...,  0.00032168,\n",
       "        -0.00030704,  0.02384648], shape=(1536,), dtype=float32),\n",
       " array([ 0.03734194, -0.02225533, -0.03487552, ..., -0.00268827,\n",
       "         0.0150866 ,  0.02299295], shape=(1536,), dtype=float32),\n",
       " array([ 0.02712595, -0.01438375,  0.05812704, ..., -0.00173069,\n",
       "        -0.00612218,  0.03404199], shape=(1536,), dtype=float32),\n",
       " array([ 0.0562048 ,  0.03134195, -0.00875072, ..., -0.01135816,\n",
       "        -0.0010601 ,  0.0051227 ], shape=(1536,), dtype=float32),\n",
       " array([ 0.05124796,  0.03914956,  0.00615394, ..., -0.00534215,\n",
       "         0.02914613,  0.01050099], shape=(1536,), dtype=float32),\n",
       " array([ 0.0493216 , -0.01986491,  0.05524438, ...,  0.00437657,\n",
       "        -0.01371937,  0.00391467], shape=(1536,), dtype=float32),\n",
       " array([ 0.04729202, -0.02137262,  0.04288136, ..., -0.00247589,\n",
       "         0.00701076,  0.01370162], shape=(1536,), dtype=float32),\n",
       " array([ 0.01731944, -0.01869224,  0.02283836, ..., -0.002262  ,\n",
       "         0.02075837, -0.00875679], shape=(1536,), dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a79e0684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': 0,\n",
       "  'chunk': 'General research interests topics are Wireless Communication, Cooperative Cognitive Communication, Wireless Sensor Networks (WSNs), \\nand Internet of Things (IoT). Currently, I am involved with secure wireless communication for the future generation networks using physical \\nlayer security techniques.\\n\\nDoctoral Thesis \\n\\nResearch Topic: Physical Layer Security for V2X-enabled Cooperative and Cognitiv'},\n",
       " {'chunk_id': 1,\n",
       "  'chunk': '\\n\\nDoctoral Thesis \\n\\nResearch Topic: Physical Layer Security for V2X-enabled Cooperative and Cognitive Relay Networks.\\n\\nSupervisor: Dr. Suneel Yadav, Assistant Professor, IIIT Allahabad.\\n\\nBrief Overview: Cooperative vehicular relaying networks (CVRNs) support various key intelligent transportation \\napplication services such as traffic management, payment services, infotainment etc. These CVRNs are '},\n",
       " {'chunk_id': 2,\n",
       "  'chunk': 'pplication services such as traffic management, payment services, infotainment etc. These CVRNs are paving the \\nway for the development of a new paradigm called Internet of Vehicles (IoV). Such networks will require the information exchange \\nto occur between the vehicles, infrastructure, users, and the Internet mostly over an open and vulnerable wireless medium. \\nThus securing the transmissions at'},\n",
       " {'chunk_id': 3,\n",
       "  'chunk': 'the Internet mostly over an open and vulnerable wireless medium. \\nThus securing the transmissions at the physical layer becomes essential. The objective in this work is to investigate the \\npotential benefits of physical layer security (PHY-security) for providing information security in CVRNs under cognitive and non-cognitive scenarios.\\n\\nM.Tech. Thesis\\n\\nResearch Topic: Intra-Cluster Community Mech'},\n",
       " {'chunk_id': 4,\n",
       "  'chunk': 'cognitive and non-cognitive scenarios.\\n\\nM.Tech. Thesis\\n\\nResearch Topic: Intra-Cluster Community Mechanism for Energy Efficiency and Data Resolution in Wireless Sensor Network.\\n\\nSupervisor: Dr. K.K. Pattanaik, Associate Professor, ABV-IIITM Gwalior.\\n\\nBrief Overview: Clustering scheme is effective in large scale densely deployed Wireless Sensor Networks (WSN). \\nPerforming data aggregation at cluster'},\n",
       " {'chunk_id': 5,\n",
       "  'chunk': 'large scale densely deployed Wireless Sensor Networks (WSN). \\nPerforming data aggregation at cluster head (CH) or compressing the data traffic originating from spatially correlated nodes \\ndoes not resolve the redundant traffic within the cluster and causes energy wastage. Selecting one node at a time among the \\ncorrelated ones affects the data resolution. The novelty of this work lied in eliminati'},\n",
       " {'chunk_id': 6,\n",
       "  'chunk': 'e among the \\ncorrelated ones affects the data resolution. The novelty of this work lied in eliminating the redundant transmissions \\nthrough designing a novel community of spatially correlated nodes within the cluster and then using average consensus \\nmechanism for an efficient data aggregation. The above mechanism resulted in considerable reduction of redundant traffic, energy consumption, channel'},\n",
       " {'chunk_id': 7,\n",
       "  'chunk': 'above mechanism resulted in considerable reduction of redundant traffic, energy consumption, channel \\ncontention and better GTS slot assignment while preserving data resolution. The above system was verified through both mathematical and \\nsimulation in OPNET Network simulator.'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b33418ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(emb_list)  # numpy array of float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5496685",
   "metadata": {},
   "source": [
    "We need to convert the list type of data to numpy vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1c7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = np.vstack(emb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbafdf",
   "metadata": {},
   "source": [
    "We need now to send this data to FAISS for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23e53451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "faiss.normalize_L2(xb)  # should be 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a33377e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68dc7e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(d)  # Using Inner Product (IP) for cosine similarity d =1536\n",
    "index.add(xb)  # add vectors to the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99497c",
   "metadata": {},
   "source": [
    "By above, we have stored above data. The above two lines are only storing data inside FAISS. \n",
    "\n",
    "index = faiss.IndexFlatIP(d)  # Using Inner Product (IP) for cosine similarity d =1536\n",
    "index.add(xb)  # add vectors to the \n",
    "\n",
    "\n",
    "All other steps were just data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef1523dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presently the data is avialable in a memory and now this data has to be stored ij a file\n",
    "\n",
    "index_path = \"index_anshul.faiss\"\n",
    "meta_path = \"meta_anshul.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0356c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, index_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c25d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f49bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path, 'w') as f:\n",
    "    for item in meta:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b4782",
   "metadata": {},
   "source": [
    "Now, the files are created and can be used whenever, requird. Next steps is \"SEARCHING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23de04c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.50643706, 0.44751012, 0.41063118, 0.40908074, 0.28474218]],\n",
       "       dtype=float32),\n",
       " array([[4, 1, 0, 3, 7]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What was anshul thesis topic in M.Tech?\"\n",
    "xq = generate_embeddings(query).astype('float32').reshape(1, -1)\n",
    "faiss.normalize_L2(xq)  # should be 1.0\n",
    "index.search(xq, k=5)  # search the top k, k represent topmost k results based on similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebf7cd",
   "metadata": {},
   "source": [
    "To understand normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdbad7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1, 2, 34, 5, 6]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cc312d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2., 34.,  5.,  6.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1252d947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(34.957115)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b0692370",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.normalize_L2(test)  # should be 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aaa512c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e85b32",
   "metadata": {},
   "source": [
    "np.linalg.norm(test)----------cALCULATES THE NORM FOR THE VECTOR Test.\n",
    "\n",
    "faiss.normalize_L2(test)----------- Normalizes\n",
    "\n",
    "after applying faiss.normalize_L2(test), if we apply and check norm with np.linalg.norm(test), we will get 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2529f103",
   "metadata": {},
   "source": [
    "Some other data base:\n",
    "\n",
    "1. Qdrant Vector Database\n",
    "2. Chromadb\n",
    "3. Weaviate\n",
    "2. Pinecone"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectorDB",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
